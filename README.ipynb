{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Section B: Practical assignment<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4> I have performed start to end ETL process in python itself.\n",
    "  Please follow the steps to know how to run the code <br/> \n",
    " Schema creation is also done in python using psycopg2 package <h4/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Requirements </h2>\n",
    "\n",
    "<h3> Tools </h3>\n",
    "1.\tPostgreSQL Server - I have used PostgreSQL server as a database server to store the given CSV file data. <br> \n",
    "2.\tAnaconda (Spyder) â€“ I have used python as programming language for ETL process <br>\n",
    "<h3> Python Packages </h3>\n",
    "psycopg2, Panadas, datetime, re, relativedelta\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Steps to follow (for windows OS) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDownload and install PostgreSQL server from the official PostgreSQL site.\n",
    "During installation process, it asks for admin username and password. It is important to remember username and password for later usage.\n",
    "2.\tNext run pgAdmin 4 app, a web page will open in internet browser. So now create a database\n",
    "by entering any name for database and admin password.\n",
    "3.\tDownload and Install Anaconda application. Also install python packages mentioned above.\n",
    "4.\tClone my git-repository and open main.py file through spyder application. In main function edit connection_params.\n",
    "5.  After editing database, user and password parameters run the code.\n",
    "6. Now schemas will be created and data will be loaded into respective tables.\n",
    "\n",
    "<h3> Important Note:  </h3> \n",
    "<br/>\n",
    "1. I have added functions to drop tables and create tables every time code is ran just to avoid constraints error while loading data.\n",
    "<br/> <br/>\n",
    "2. Transaction_ID is added as a primary key in Transaction table. Since Transaction ID is unique, there are lots of redundant transaction IDs in given file. Only first such transaction ID is kept and remaining correspnding rows are removed. So final query result may vary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. How malformed data is handled </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Handling NaN values - Phone Numbers are not provided in customer csv file. So while inseerting data into database theses NaN valeus are converted into NULL values.\n",
    "2. Birth_Date in customer csv file has two types of date formats. And hence are converted into SQL date format before inserting into database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. SQL query to generate the report </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select c.id_person,date_trunc ('month', t.transaction_date) as month , \n",
    "sum(transaction_amount) as sum_of_transactions\n",
    "from transaction t,customer c,account a\n",
    "where t.id_account = a.id_account and a.id_person = c.id_person and\n",
    "c.id_person in (345,1234)\n",
    "and (t.transaction_date Between '2020-02-15' AND '2020-06-06')\n",
    "GROUP BY month,c.id_person\n",
    "ORDER BY c.id_person,month DESC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
